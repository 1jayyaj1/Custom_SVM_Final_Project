{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECSE415_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o91lCmRsPHeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a85e19-a76d-4cf8-810e-b182d82145ea"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numpy import random\n",
        "from sklearn.svm import SVC\n",
        "import csv \n",
        "from shapely.geometry import Point, Polygon\n",
        "from skimage import feature\n",
        "import os\n",
        "import cvxopt\n",
        "import cvxopt.solvers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# path = '/content/drive/MyDrive/Colab_Notebooks/ECSE415_Final_Project/' # Kun's path, comment out when needed\n",
        "path = '/content/drive/MyDrive/Colab_Notebooks/ECSE415_Final_Project/' # Jay's path\n",
        "# path = '/content/drive/My Drive/ECSE_415/Project/' # Ben's path\n",
        "# path = './' # Kamy's path"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gPBMfM_Csk1"
      },
      "source": [
        "[Add a couple sentences to describe code below (like I did for the code boxes below)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4Ag07uPJPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "tags": [],
        "outputId": "4df3dd28-068f-4bf4-b298-4ce752a5fe4c"
      },
      "source": [
        "# Inspired from https://medium.com/@luanaebio/detecting-people-with-yolo-and-opencv-5c1f9bc6a810\n",
        "\n",
        "images = []\n",
        "path_frames = path + 'frames/'\n",
        "detected_frames = []\n",
        "positive_patches = []\n",
        "negative_patches = []\n",
        "boxes_positive_patches_array = []\n",
        "\n",
        "# load images from frames/\n",
        "for count,image_path in enumerate(os.listdir(path_frames)):\n",
        "  if count > 30:\n",
        "    break\n",
        "  input_path = os.path.join(path_frames, image_path)\n",
        "  image = plt.imread(input_path)\n",
        "  images.append(image)\n",
        "\n",
        "Width = image.shape[1]\n",
        "Height = image.shape[0]\n",
        "\n",
        "# load class names\n",
        "classes = None\n",
        "with open(path + 'coco.names', 'r') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# read pre-trained model and config file\n",
        "net = cv2.dnn.readNet(path + 'yolov3.weights', path + 'cfg/yolov3.cfg')\n",
        "\n",
        "for image in images:\n",
        "  image_patches = image.copy()\n",
        "\n",
        "  # create input blob \n",
        "  # set input blob for the network\n",
        "  # blob = cv2.dnn.blobFromImage(image, scalefactor=?, size=?, mean substraction value=?, swapRB=?)\n",
        "  blob = cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False)\n",
        "  net.setInput(blob)\n",
        "\n",
        "  # run inference through the network\n",
        "  layer_names = net.getLayerNames()\n",
        "  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "  # gather predictions from output layers\n",
        "  outs = net.forward(output_layers)\n",
        "\n",
        "  # initiatialization\n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = []\n",
        "  conf_threshold = 0.5\n",
        "  nms_threshold = 0.4\n",
        "  boxes_positive_patches = []\n",
        "\n",
        "  # for each detetion from each output layer get the confidence, class id, bounding box params and ignore weak detections (confidence < 0.5) \n",
        "  for out in outs:\n",
        "    for detection in out:\n",
        "      scores = detection[5:] # from 0-4, is matched box coordinates/dimension info, from 5 onwards is an array of confidence scores towards each different class in classes\n",
        "      class_id = np.argmax(scores) # return the index of max confidence\n",
        "      confidence = scores[class_id] # get the confidence score\n",
        "      if confidence > conf_threshold:\n",
        "        center_x = int(detection[0] * Width)\n",
        "        center_y = int(detection[1] * Height)\n",
        "        w = int(detection[2] * Width)\n",
        "        h = int(detection[3] * Height)\n",
        "        x = center_x - w / 2\n",
        "        y = center_y - h / 2\n",
        "\n",
        "        #####################################\n",
        "        #                                   #\n",
        "        #  moved \"extract positive patches\" #\n",
        "        #  part from here to post NMS to    #\n",
        "        #  further remove duplicated ones   #\n",
        "        #                                   #\n",
        "        #####################################\n",
        "\n",
        "        # store captured class_id number\n",
        "        class_ids.append(class_id)\n",
        "        # store the confidence towards the above class_id\n",
        "        confidences.append(float(confidence))\n",
        "        # store the captured boxes\n",
        "        boxes.append([x, y, w, h])\n",
        "        # Would need to generate negative patch here and append it to negative_patches array\n",
        "\n",
        "  # apply non-max suppression: extract the highest confidence box index among all partially overlapped boxes\n",
        "  indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold )\n",
        "\n",
        "  #print(\"Positive patches of this image:\")\n",
        "\n",
        "  #check if is people detection, if so, draw boxes in the original image, and extract positive patches\n",
        "  for i in indices:\n",
        "    i = i[0] # i was a 1x1 array, make it a scaler for indexing into boxes\n",
        "    box = boxes[i]\n",
        "    if class_ids[i]==0:\n",
        "      label = str(classes[class_id])\n",
        "\n",
        "      ################ extract positive patches starts ##############\n",
        "\n",
        "      x = box[0]\n",
        "      y = box[1]\n",
        "      w = box[2]\n",
        "      h = box[3]\n",
        "      if w > 100 or w < 1 or h > 200 or h < 1:\n",
        "        continue\n",
        "      positive_patch = np.squeeze(image_patches)\n",
        "      positive_patch = positive_patch[int(y):int(y+h),int(x):int(x+w)]\n",
        "      positive_patches.append(positive_patch)\n",
        "\n",
        "      # extract positive patch box in an array \n",
        "      boxes_positive_patches.append(box)\n",
        "\n",
        "      ############ show positive patches ############\n",
        "\n",
        "      # plt.imshow(positive_patch)\n",
        "      # plt.show()\n",
        "\n",
        "      ############### extract positive patches end #################\n",
        "      \n",
        "      # draw selected boxes in the original image\n",
        "      cv2.rectangle(image, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (255, 0, 0), 2)\n",
        "      cv2.putText(image, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "  ############## extract negative patches start ###############\n",
        "\n",
        "  #print(\"Negative patches of this image\")\n",
        "\n",
        "  # foreach positie patch, create a negative patch at a random location that does not intersect with any of the positive patches\n",
        "  for boxA in boxes_positive_patches:\n",
        "\n",
        "    # extract positive patch dimension\n",
        "    wA = boxA[2]\n",
        "    hA = boxA[3]\n",
        "\n",
        "    max_xA1 = Width - wA\n",
        "    max_yA1 = Height - hA\n",
        "\n",
        "    # initialize the random image status to dirty until loop through all positive patches to confirm no intersactions\n",
        "    n_patch_status = 'dirty'\n",
        "\n",
        "    # generate negative patch candidates if patch status is 'dirty'\n",
        "    while n_patch_status == 'dirty':\n",
        "      # generate a negative patch candidate with the same dimension as the positive patch but located randomly elsewhere in the image\n",
        "      xA1 = np.random.randint(0,max_xA1)\n",
        "      yA1 = np.random.randint(0,max_yA1)\n",
        "      xA2 = xA1 + wA\n",
        "      yA2 = yA1 + hA\n",
        "      polyA = Polygon([(xA1,yA1),(xA2,yA1),(xA2,yA2),(xA1,yA2),(xA1,yA1)])\n",
        "      # p1 = Point(xA1,yA1)\n",
        "      # p2 = Point(xA1,yA2)\n",
        "      # p3 = Point(xA2,yA1)\n",
        "      # p4 = Point(xA2,yA2)\n",
        "      # print (f'w range: {wA}, h range: {hA}, xA1 = {xA1}, yA1 = {yA1}')\n",
        "      # check the negative patch candidate against each of the positive patches\n",
        "      for boxB in boxes_positive_patches:\n",
        "        xB1 = boxB[0]\n",
        "        yB1 = boxB[1]\n",
        "        wB = boxB[2]\n",
        "        hB = boxB[3]\n",
        "        xB2 = xB1 + wB\n",
        "        yB2 = yB1 + hB\n",
        "        polyB = Polygon([(xB1,yB1),(xB2,yB1),(xB2,yB2),(xB1,yB2),(xB1,yB1)])\n",
        "        #if ((xB1<=xA1<=xB2 and yB1<=yA1<=yB2) or (xB1<=xA1<=xB2 and yB1<=yA1<=yB2) or (xB1<=xA1<=xB2 and yB1<=yA1<=yB2))\n",
        "        # if any corner of the negative patch candidate falls within the positive patch, disregard and generate a new one\n",
        "        #if p1.within(polyB) == 'True' or p2.within(polyB) == 'True' or p3.within(polyB) == 'True' or p4.within(polyB) == 'True':\n",
        "        if Polygon(polyA).intersects(Polygon(polyB)):\n",
        "          n_patch_status = 'dirty'\n",
        "          break\n",
        "        # else temporarily set the negative patch candidate as clean\n",
        "        else:\n",
        "          n_patch_status = 'clean'\n",
        "      # after a particular negative patch candidate has been confirmed not intersecting with any of the positive patches, extract it.\n",
        "      if n_patch_status == 'clean':\n",
        "        negative_patch = np.squeeze(image_patches)\n",
        "        negative_patch = negative_patch[int(yA1):int(yA2),int(xA1):int(xA2)]\n",
        "        negative_patches.append(negative_patch)\n",
        "\n",
        "        ########### show negative patches ###########\n",
        "\n",
        "        # plt.imshow(negative_patch)\n",
        "        # plt.show()\n",
        "\n",
        "  ############## extract negative patches end ###############\n",
        "\n",
        "  detected_frames.append(image)\n",
        "  boxes_positive_patches_array.append(boxes_positive_patches)\n",
        "\n",
        "  ########### show image ########### \n",
        "\n",
        "  #show image\n",
        "  # print(\"This image:\")\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "\n",
        "print('Detected people in ' + str(len(detected_frames)) + ' frames which are stored in the detected_images array')\n",
        "print('Extracted ' + str(len(positive_patches)) + ' positive patches which are stored in the positive_patches array')\n",
        "print('Extracted ' + str(len(negative_patches)) + ' negative patches which are stored in the negative_patches array')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected people in 31 frames which are stored in the detected_images array\n",
            "Extracted 610 positive patches which are stored in the positive_patches array\n",
            "Extracted 610 negative patches which are stored in the negative_patches array\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8co3Isb_caK"
      },
      "source": [
        "Since our patches will have different dimensions, we decided to use LBP instead of HoG features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHnt5lFWxTmi"
      },
      "source": [
        "# Inspired from https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
        "\n",
        "# Compute histogram of Local Binary Pattern (LBP) features for each input image\n",
        "def LBP(images, numPoints, radius, eps=1e-7):\n",
        "  features = []\n",
        "  for count,image in enumerate(images):\n",
        "    # Only compute LBP feautres for non-empty images\n",
        "    if image.shape[1] != 0:\n",
        "      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # LBP representation\n",
        "      lbp = feature.local_binary_pattern(gray, numPoints, radius, method=\"uniform\")\n",
        "      \n",
        "      # Build histogram of LBP representation\n",
        "      (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, numPoints + 3), range=(0, numPoints + 2))\n",
        "\n",
        "      # Normalize the histogram\n",
        "      hist = hist.astype(\"float\")\n",
        "      hist /= (hist.sum() + eps)\n",
        "\n",
        "      # Return the histogram of Local Binary Patterns\n",
        "      features.append(hist)\n",
        "  return features"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcKGhe94_v6S"
      },
      "source": [
        "We can now compute the LBP histogram for both the negative and positive patches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPeehCrl3xqR"
      },
      "source": [
        "# Compute LBP histogram for positive patches extracted\n",
        "positive_patches_LBP = LBP(images=np.array(positive_patches), numPoints=24, radius=8)\n",
        "\n",
        "# Compute LBP histogram for negative patches extracted\n",
        "negative_patches_LBP = LBP(images=np.array(negative_patches), numPoints=24, radius=8)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "509ekIGv_4KG"
      },
      "source": [
        "Once we computed all LBP histograms, we can build our dataset by assiging a ground truth label of +1 for positive LBP histograms, and -1 for negative LBP histograms. Lastly, we use a built-in Scikit learn method to generate a  training and validation (test) set from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdtkdcW1s23R",
        "tags": [],
        "outputId": "4324f50a-ef2a-4ead-c123-f168ee30ea0b"
      },
      "source": [
        "x = []  # LBP histgrams\n",
        "y = []  # Corresponding ground truth label\n",
        "\n",
        "# Add LBP histograms of positive patches and their corresponding label\n",
        "for p in positive_patches_LBP:\n",
        "  x.append(p)\n",
        "  y.append(1.)\n",
        "\n",
        "# Add LBP histograms of negative patches and their corresponding label\n",
        "for n in negative_patches_LBP:\n",
        "  x.append(n)\n",
        "  y.append(-1.)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# Generate training and validation (test) set by using Scikit learn method\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
        "\n",
        "# Print shape of final training and validation (test) sets\n",
        "print('X_train shape: ' + str(X_train.shape))\n",
        "print('y_train shape: ' + str(y_train.shape) + '\\n')\n",
        "print('X_test shape: ' + str(X_test.shape))\n",
        "print('y_test shape: ' + str(y_test.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (913, 26)\n",
            "y_train shape: (913,)\n",
            "\n",
            "X_test shape: (305, 26)\n",
            "y_test shape: (305,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C43dGoiAWkp"
      },
      "source": [
        "To fit and predict our data, we opted with a custom implementation of a non-linear SVM which used the radial basis function (rbf) which was found to yield better results than the polynomial function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFrcTyTX88dO"
      },
      "source": [
        "class SVM():\n",
        "  def __init__(self):\n",
        "    # Params will be set throughout the lifecycle of the SVM object\n",
        "    self.SV = None\n",
        "    self.SL = None\n",
        "    self.support = None\n",
        "    self.alphas = None\n",
        "    self.intercept = None\n",
        "    self.indices = None\n",
        "    self.weights = None\n",
        "  \n",
        "  # Non-linear function used for our SVM\n",
        "  def radial_basis_function(self, x, y):\n",
        "    gamma = 10.\n",
        "    x_y = np.subtract(x, y)\n",
        "    x_y_trans = x_y.T\n",
        "    return np.exp(-(gamma * np.dot(x_y_trans, x_y)))\n",
        "\n",
        "  # Trains our SVM\n",
        "  def fit(self, data, labels):\n",
        "    d_count, _ = data.shape\n",
        "    \n",
        "    # Create initial transforms\n",
        "    k = np.zeros([d_count,d_count])\n",
        "    for i in range(d_count):\n",
        "      for j in range(d_count):\n",
        "        k[i,j] = self.radial_basis_function(data[i],data[j])\n",
        "\n",
        "    # Defining required variables for CVXOPT used for convex optimization purposes\n",
        "    P = cvxopt.matrix(np.outer(labels,labels)*k)\n",
        "    q = cvxopt.matrix(np.ones(d_count)*-1)\n",
        "    G = cvxopt.matrix(np.diag(np.ones(d_count) * -1))\n",
        "    h = cvxopt.matrix(np.zeros(d_count))\n",
        "    A = cvxopt.matrix(labels,(1,d_count))\n",
        "    b = cvxopt.matrix(0.0)\n",
        "\n",
        "    # Solving for x\n",
        "    target = 'x'\n",
        "    res = cvxopt.solvers.qp(P, q, G, h, A, b)[target]\n",
        "    res_flat = np.ravel(res)\n",
        "    select = res_flat > 1e-5\n",
        "\n",
        "    # Setting the different class variables from the results we got from CVXOPT\n",
        "    self.intercept = 0\n",
        "    self.SV = data[select]\n",
        "    self.SL = labels[select]\n",
        "    self.alphas = res_flat[select]\n",
        "    self.indices = np.arange(d_count)[select]\n",
        "    self.support = np.sum(select)\n",
        "\n",
        "    # Optimize\n",
        "    count = self.alphas.shape[0]\n",
        "    for index in range(count):\n",
        "      self.intercept += self.SL[index]\n",
        "      transform = k[self.indices[index], select]\n",
        "      curr = transform * self.SL * self.alphas\n",
        "      self.intercept -= np.sum(curr)\n",
        "    self.intercept /= count\n",
        "\n",
        "  # Predicts using our trained SVM\n",
        "  def predict(self, data):\n",
        "    size = data.shape[0]\n",
        "    res = np.zeros(size)\n",
        "    for i in range(size):\n",
        "      s = 0\n",
        "      # Assuming alphas SL and SV have same size\n",
        "      for j in range(len(self.SV)):\n",
        "        a = self.alphas[j]\n",
        "        l = self.SL[j]\n",
        "        sv = self.SV[j]\n",
        "        s += a * l * self.radial_basis_function(data[i], sv)\n",
        "      res[i] = s\n",
        "    res += self.intercept\n",
        "    return np.where(res>0,1,-1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m9jJZMlAouQ"
      },
      "source": [
        "At this point, we're ready to test our SVM classifier. To do so, we compare it to the built-in non-linear SVM from Scikit learn. We start by instantiating both classifiers and train them on the same training set that we built earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY1ekm4-9B6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d85bcc0-9c93-41d7-8437-75a060a490b4"
      },
      "source": [
        "# Instantiate our custom non-linear SVM using a radial basis function (rbf)\n",
        "model_custom = SVM()\n",
        "\n",
        "# Fit our custom non-linear SVM with the dataset built earlier\n",
        "model_custom.fit(X_train, y_train)\n",
        "\n",
        "# For comparison, instantiate Scikit learn non-linear SVM using a radial basis function (rbf)\n",
        "model_scikit = SVC(kernel='rbf')\n",
        "\n",
        "# Fit the Scikit learn non-linear SVM with the same dataset built earlier\n",
        "model_scikit.fit(X_train, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -5.7653e+02 -1.7708e+03  4e+03  4e+01  3e+00\n",
            " 1: -1.9888e+03 -3.7087e+03  3e+03  2e+01  2e+00\n",
            " 2: -3.1923e+03 -5.3933e+03  3e+03  2e+01  2e+00\n",
            " 3: -8.5790e+03 -1.1093e+04  3e+03  2e+01  1e+00\n",
            " 4: -2.4164e+04 -2.8566e+04  5e+03  2e+01  1e+00\n",
            " 5: -7.5078e+04 -8.4562e+04  1e+04  1e+01  1e+00\n",
            " 6: -1.9260e+05 -2.1230e+05  2e+04  1e+01  1e+00\n",
            " 7: -4.1297e+05 -4.5029e+05  4e+04  1e+01  1e+00\n",
            " 8: -9.7986e+05 -1.0622e+06  8e+04  1e+01  1e+00\n",
            " 9: -1.8817e+06 -2.0442e+06  2e+05  1e+01  1e+00\n",
            "10: -4.0417e+06 -4.4579e+06  4e+05  1e+01  1e+00\n",
            "11: -8.2923e+06 -9.4766e+06  1e+06  1e+01  1e+00\n",
            "12: -1.6052e+07 -1.9327e+07  3e+06  1e+01  9e-01\n",
            "13: -2.6343e+07 -3.2554e+07  6e+06  8e+00  6e-01\n",
            "14: -3.1024e+07 -3.2334e+07  1e+06  3e-09  3e-09\n",
            "15: -3.1181e+07 -3.1234e+07  5e+04  1e-09  4e-09\n",
            "16: -3.1194e+07 -3.1195e+07  1e+03  3e-09  4e-09\n",
            "17: -3.1194e+07 -3.1194e+07  3e+01  3e-09  4e-09\n",
            "Optimal solution found.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz2GQMLJBta8"
      },
      "source": [
        "Once both classifiers are trained on the same data, the last step of the comparison is to compare their respective predictions for the same test set that we built earlier. As we can see, our custom non-linear SVM using rbf perfoms slightly better than the Scikit learn, which is a good sign. After testing it on different data, we noticed that our classifier consistently outperforms the one from Scikit learn. Therefore, we conclude that our SVM's performance is adequate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4JzQONh8-Sf",
        "tags": [],
        "outputId": "6ac42777-b4dd-43f5-d756-e42ab2fe90e7"
      },
      "source": [
        "# Used our trained custom non-linear SVM to predict labels from the test set built earlier\n",
        "prediction_custom = model_custom.predict(X_test)\n",
        "\n",
        "# Used the Scikit learn non-linear SVM to predict labels from the same test set built earlier\n",
        "prediction_scikit = model_scikit.predict(X_test)\n",
        "\n",
        "correct_custom = 0\n",
        "correct_scikit = 0\n",
        "\n",
        "# Compare each predictions to the expected labels (ground truth)\n",
        "for i in range(len(list(y_test))):\n",
        "  if y_test[i] == prediction_custom[i]:\n",
        "    correct_custom += 1\n",
        "  if y_test[i] == prediction_scikit[i]:\n",
        "    correct_scikit += 1\n",
        "\n",
        "# Display classification accuracy for both our custom SVM as well as the Scikit learn one\n",
        "print('The accuracy from our custom non-linear SVM on the test set is: ' + str('{:.2f}'.format(correct_custom/len(list(y_test)) * 100)) + '%\\n')\n",
        "print('The accuracy from the Scikit learn non-linear SVM on the test set is: ' + str('{:.2f}'.format(correct_scikit/len(list(y_test)) * 100)) + '%')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy from our custom non-linear SVM on the test set is: 78.36%\n",
            "\n",
            "The accuracy from the Scikit learn non-linear SVM on the test set is: 75.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA9p8TpRCbwT"
      },
      "source": [
        "[Add a couple sentences to describe code below (like I did for the code boxes above)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "BGAA7uGB_aAi",
        "outputId": "d05f743a-b2e2-475a-c1b8-f90972753a7a"
      },
      "source": [
        "predictions_per_image = []\n",
        "svm_boxes_array = []\n",
        "for count,image_path in enumerate(os.listdir(path_frames)):\n",
        "    if count >= len(detected_frames):\n",
        "        break\n",
        "    #sliding window along one frame\n",
        "    input_path = os.path.join(path_frames, image_path)\n",
        "    image = plt.imread(input_path)\n",
        "    # print(image.shape)\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "    windows = []\n",
        "    our_boxes = []\n",
        "    #sliding window, window size grows as we go down\n",
        "    for a in range(0,621,20):\n",
        "        for b in range(0,101,50):\n",
        "            temp_image = image[b:b+50,a:a+20]\n",
        "            windows.append(temp_image)\n",
        "            our_boxes.append([b, a, 50, 20])\n",
        "    for a in range(0,601,40):\n",
        "        for b in range(100,301,50):\n",
        "            temp_image = image[b:b+90,a:a+40]\n",
        "            windows.append(temp_image)\n",
        "            our_boxes.append([b, a, 90, 40])\n",
        "    for a in range(0,591,10):\n",
        "        for b in range(300,381,80):\n",
        "            temp_image = image[b:b+100,a:a+50]\n",
        "            windows.append(temp_image)\n",
        "            our_boxes.append([b, a, 100, 50])\n",
        "\n",
        "\n",
        "    # plt.figure(figsize=(5, 5))\n",
        "    # plt.imshow(windows[-1])\n",
        "    # plt.show()\n",
        "    # print('Detected ' + str(len(windows)) + ' windows.')\n",
        "\n",
        "    np_windows = np.array(windows)\n",
        "    # print(np_windows.shape)\n",
        "    # print(\"getting features\")\n",
        "    test_windows = LBP(images=np_windows, numPoints=24, radius=8)\n",
        "    # print(\"making predictions\")\n",
        "    predictions = model.predict(np.array(test_windows))\n",
        "    #put in seperate block so you don't rerun the last block\n",
        "    pos_windows = []\n",
        "    our_pos_boxes = []\n",
        "    for i in range(len(predictions)):\n",
        "        if (predictions[i] == 1):\n",
        "            pos_windows.append(np_windows[i])\n",
        "            our_pos_boxes.append(our_boxes[i])\n",
        "    np_pos_windows = np.array(pos_windows)\n",
        "\n",
        "    # print(np_pos_windows.shape)\n",
        "    # for im in np_pos_windows:\n",
        "    #   plt.imshow(im)\n",
        "    #   plt.show()\n",
        "\n",
        "\n",
        "    delete = []\n",
        "    for f in range(np_pos_windows.shape[0]):\n",
        "        delete.append(1)\n",
        "    for a in range(np_pos_windows.shape[0]):\n",
        "        if (delete[a] == 1):\n",
        "            hsv1 = cv2.cvtColor(np_pos_windows[a], cv2.COLOR_BGR2HSV)\n",
        "            hist1 = cv2.calcHist([hsv1], [0,1], None, [180,256], [0,180,0,256])\n",
        "            cv2.normalize(hist1, hist1, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "            for b in range(np_pos_windows.shape[0]):\n",
        "                if (delete[b]==1):\n",
        "                    hsv2 = cv2.cvtColor(np_pos_windows[b], cv2.COLOR_BGR2HSV)\n",
        "                    hist2 = cv2.calcHist([hsv2], [0,1], None, [180,256], [0,180,0,256])\n",
        "                    cv2.normalize(hist2, hist2, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "                    difference = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
        "                    #print(difference)\n",
        "                    if (difference > 0.30 and b != a):\n",
        "                        delete[b] = 0\n",
        "\n",
        "    # print(delete)\n",
        "\n",
        "    im = image.copy()\n",
        "    people_count = 0\n",
        "    positive_boxes = []\n",
        "    for i in range(len(np_pos_windows)):\n",
        "        if (delete[i] != 0):\n",
        "            # draw selected boxes in the original image\n",
        "            cv2.rectangle(im, (round(our_pos_boxes[i][1]),round(our_pos_boxes[i][0])), (round(our_pos_boxes[i][1]+our_pos_boxes[i][3]),round(our_pos_boxes[i][0]+our_pos_boxes[i][2])), (255, 0, 0), 2)\n",
        "            people_count += 1\n",
        "            positive_boxes.append(our_pos_boxes[i])\n",
        "\n",
        "    # only keep as many boxes as yolo frames for IoU computation\n",
        "    if count < len(detected_frames):\n",
        "        svm_boxes_array.append(positive_boxes)\n",
        "        print(count)\n",
        "                \n",
        "        \n",
        "    # plt.figure(figsize=(15, 15))\n",
        "    # plt.imshow(im)\n",
        "    # plt.show()\n",
        "    print(\"image: \" + str(image_path) + \" people count: \" + str(people_count)) \n",
        "    predictions_per_image.append([count+1, people_count])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "image: seq_000001.jpg people count: 26\n",
            "1\n",
            "image: seq_000002.jpg people count: 21\n",
            "2\n",
            "image: seq_000003.jpg people count: 26\n",
            "3\n",
            "image: seq_000004.jpg people count: 25\n",
            "4\n",
            "image: seq_000005.jpg people count: 27\n",
            "5\n",
            "image: seq_000006.jpg people count: 27\n",
            "6\n",
            "image: seq_000007.jpg people count: 37\n",
            "7\n",
            "image: seq_000008.jpg people count: 29\n",
            "8\n",
            "image: seq_000009.jpg people count: 24\n",
            "9\n",
            "image: seq_000010.jpg people count: 27\n",
            "10\n",
            "image: seq_000011.jpg people count: 29\n",
            "11\n",
            "image: seq_000012.jpg people count: 29\n",
            "12\n",
            "image: seq_000013.jpg people count: 37\n",
            "13\n",
            "image: seq_000014.jpg people count: 29\n",
            "14\n",
            "image: seq_000015.jpg people count: 36\n",
            "15\n",
            "image: seq_000016.jpg people count: 24\n",
            "16\n",
            "image: seq_000017.jpg people count: 23\n",
            "17\n",
            "image: seq_000018.jpg people count: 21\n",
            "18\n",
            "image: seq_000019.jpg people count: 33\n",
            "19\n",
            "image: seq_000020.jpg people count: 33\n",
            "20\n",
            "image: seq_000021.jpg people count: 30\n",
            "21\n",
            "image: seq_000022.jpg people count: 29\n",
            "22\n",
            "image: seq_000023.jpg people count: 31\n",
            "23\n",
            "image: seq_000024.jpg people count: 29\n",
            "24\n",
            "image: seq_000025.jpg people count: 23\n",
            "25\n",
            "image: seq_000026.jpg people count: 30\n",
            "26\n",
            "image: seq_000027.jpg people count: 34\n",
            "27\n",
            "image: seq_000028.jpg people count: 30\n",
            "28\n",
            "image: seq_000029.jpg people count: 21\n",
            "29\n",
            "image: seq_000030.jpg people count: 28\n",
            "30\n",
            "image: seq_000031.jpg people count: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjMiHQF1Cli7"
      },
      "source": [
        "[Add a couple sentences to describe code below (like I did for the code boxes above)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "tM1wvi6c_aAj",
        "outputId": "217fba6c-f1f0-465c-cf04-2cab9dd24801"
      },
      "source": [
        "# Making masks from bounding boxes for each frame\n",
        "def make_mask(frame, bounding_boxes, yolo=True):\n",
        "    # \ta- initialise mask (numpy array) of frame size to 0s.\n",
        "    mask = np.zeros((frame.shape[0], frame.shape[1]))\n",
        "    # \tb- for each bounding box in frame, set \n",
        "    for box in bounding_boxes:\n",
        "        x = int(box[0])\n",
        "        y = int(box[1])\n",
        "        w = int(box[2])\n",
        "        h = int(box[3])\n",
        "        ## TODO: FIX THE BOX X,Y Conventions to avoid the code below\n",
        "        if yolo:\n",
        "            mask[y: y+h, x: x+w] = 255\n",
        "        else: \n",
        "            mask[x: x+w, y: y+h] = 255\n",
        "\n",
        "    \n",
        "    return mask\n",
        "\n",
        "# Calculating IoU\n",
        "intersections = []\n",
        "unions = []\n",
        "for count, frame in enumerate(detected_frames):\n",
        "    yolo_mask = make_mask(frame, boxes_positive_patches_array[count])\n",
        "    svm_mask = make_mask(frame, svm_boxes_array[count], yolo=False)\n",
        "\n",
        "    # Calculating IoU\n",
        "    intersections.append(np.logical_and(yolo_mask, svm_mask))\n",
        "    unions.append(np.logical_or(yolo_mask, svm_mask))\n",
        "\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    # plt.imshow(yolo_mask)\n",
        "    # plt.subplot(1, 2, 2)\n",
        "    # plt.imshow(svm_mask)\n",
        "    # plt.show()\n",
        "\n",
        "print(\"IoU: \" + str(np.sum(intersections) / np.sum(unions)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IoU:0.1769772970861959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9xTKv9LCn5G"
      },
      "source": [
        "[Add a couple sentences to describe code below (like I did for the code boxes above)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "onYxT1gJ_aAk"
      },
      "source": [
        "# field names  \n",
        "fields = ['id', 'count']  \n",
        "    \n",
        "# data rows of csv file  \n",
        "rows = predictions_per_image\n",
        "\n",
        "# name of csv file  \n",
        "filename = \"group21_submission.csv\"\n",
        "    \n",
        "# writing to csv file  \n",
        "with open(filename, 'w', newline='') as csvfile:  \n",
        "    # creating a csv writer object  \n",
        "    csvwriter = csv.writer(csvfile)  \n",
        "        \n",
        "    # writing the fields  \n",
        "    csvwriter.writerow(fields)  \n",
        "        \n",
        "    # writing the data rows  \n",
        "    csvwriter.writerows(rows)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}