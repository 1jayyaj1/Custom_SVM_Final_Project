{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o91lCmRsPHeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a2457a-5ac0-4314-9ceb-961b2617f48b"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numpy import random\n",
        "from shapely.geometry import Point, Polygon\n",
        "from skimage import feature\n",
        "import os\n",
        "import cvxopt\n",
        "import cvxopt.solvers\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# path = '/content/drive/MyDrive/Colab_Notebooks/ECSE415_Final_Project/' # Kun's path, comment out when needed\n",
        "# path = '/content/drive/MyDrive/Colab_Notebooks/ECSE415_Final_Project/' # Jay's path\n",
        "# path = '/content/drive/My Drive/ECSE_415/Project/' # Ben's path\n",
        "path = './' # Kamy's path"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4Ag07uPJPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb97d25-c75d-4d07-925e-588fb64fb089",
        "tags": []
      },
      "source": [
        "# Inspired from https://medium.com/@luanaebio/detecting-people-with-yolo-and-opencv-5c1f9bc6a810\n",
        "\n",
        "images = []\n",
        "path_frames = path + 'frames/'\n",
        "detected_frames = []\n",
        "positive_patches = []\n",
        "negative_patches = []\n",
        "boxes_positive_patches_array = []\n",
        "\n",
        "# load images from frames/\n",
        "for count,image_path in enumerate(os.listdir(path_frames)):\n",
        "  if count > 30:\n",
        "    break\n",
        "  input_path = os.path.join(path_frames, image_path)\n",
        "  image = plt.imread(input_path)\n",
        "  images.append(image)\n",
        "\n",
        "Width = image.shape[1]\n",
        "Height = image.shape[0]\n",
        "\n",
        "# load class names\n",
        "classes = None\n",
        "with open(path + 'coco.names', 'r') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# read pre-trained model and config file\n",
        "net = cv2.dnn.readNet(path + 'yolov3.weights', path + 'cfg/yolov3.cfg')\n",
        "\n",
        "for image in images:\n",
        "  image_patches = image.copy()\n",
        "\n",
        "  # create input blob \n",
        "  # set input blob for the network\n",
        "  # blob = cv2.dnn.blobFromImage(image, scalefactor=?, size=?, mean substraction value=?, swapRB=?)\n",
        "  blob = cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False)\n",
        "  net.setInput(blob)\n",
        "\n",
        "  # run inference through the network\n",
        "  layer_names = net.getLayerNames()\n",
        "  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "  # gather predictions from output layers\n",
        "  outs = net.forward(output_layers)\n",
        "\n",
        "  # initiatialization\n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = []\n",
        "  conf_threshold = 0.5\n",
        "  nms_threshold = 0.4\n",
        "  boxes_positive_patches = []\n",
        "\n",
        "  # for each detetion from each output layer get the confidence, class id, bounding box params and ignore weak detections (confidence < 0.5) \n",
        "  for out in outs:\n",
        "    for detection in out:\n",
        "      scores = detection[5:] # from 0-4, is matched box coordinates/dimension info, from 5 onwards is an array of confidence scores towards each different class in classes\n",
        "      class_id = np.argmax(scores) # return the index of max confidence\n",
        "      confidence = scores[class_id] # get the confidence score\n",
        "      if confidence > conf_threshold:\n",
        "        center_x = int(detection[0] * Width)\n",
        "        center_y = int(detection[1] * Height)\n",
        "        w = int(detection[2] * Width)\n",
        "        h = int(detection[3] * Height)\n",
        "        x = center_x - w / 2\n",
        "        y = center_y - h / 2\n",
        "\n",
        "        #####################################\n",
        "        #                                   #\n",
        "        #  moved \"extract positive patches\" #\n",
        "        #  part from here to post NMS to    #\n",
        "        #  further remove duplicated ones   #\n",
        "        #                                   #\n",
        "        #####################################\n",
        "\n",
        "        # store captured class_id number\n",
        "        class_ids.append(class_id)\n",
        "        # store the confidence towards the above class_id\n",
        "        confidences.append(float(confidence))\n",
        "        # store the captured boxes\n",
        "        boxes.append([x, y, w, h])\n",
        "        # Would need to generate negative patch here and append it to negative_patches array\n",
        "\n",
        "  # apply non-max suppression: extract the highest confidence box index among all partially overlapped boxes\n",
        "  indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold )\n",
        "\n",
        "  #print(\"Positive patches of this image:\")\n",
        "\n",
        "  #check if is people detection, if so, draw boxes in the original image, and extract positive patches\n",
        "  for i in indices:\n",
        "    i = i[0] # i was a 1x1 array, make it a scaler for indexing into boxes\n",
        "    box = boxes[i]\n",
        "    if class_ids[i]==0:\n",
        "      label = str(classes[class_id])\n",
        "\n",
        "      ################ extract positive patches starts ##############\n",
        "\n",
        "      x = box[0]\n",
        "      y = box[1]\n",
        "      w = box[2]\n",
        "      h = box[3]\n",
        "      if w > 100 or w < 1 or h > 200 or h < 1:\n",
        "        continue\n",
        "      positive_patch = np.squeeze(image_patches)\n",
        "      positive_patch = positive_patch[int(y):int(y+h),int(x):int(x+w)]\n",
        "      positive_patches.append(positive_patch)\n",
        "\n",
        "      # extract positive patch box in an array \n",
        "      boxes_positive_patches.append(box)\n",
        "\n",
        "      ############ show positive patches ############\n",
        "\n",
        "      # plt.imshow(positive_patch)\n",
        "      # plt.show()\n",
        "\n",
        "      ############### extract positive patches end #################\n",
        "      \n",
        "      # draw selected boxes in the original image\n",
        "      cv2.rectangle(image, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (255, 0, 0), 2)\n",
        "      cv2.putText(image, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "  ############## extract negative patches start ###############\n",
        "\n",
        "  #print(\"Negative patches of this image\")\n",
        "\n",
        "  # foreach positie patch, create a negative patch at a random location that does not intersect with any of the positive patches\n",
        "  for boxA in boxes_positive_patches:\n",
        "\n",
        "    # extract positive patch dimension\n",
        "    wA = boxA[2]\n",
        "    hA = boxA[3]\n",
        "\n",
        "    max_xA1 = Width - wA\n",
        "    max_yA1 = Height - hA\n",
        "\n",
        "    # initialize the random image status to dirty until loop through all positive patches to confirm no intersactions\n",
        "    n_patch_status = 'dirty'\n",
        "\n",
        "    # generate negative patch candidates if patch status is 'dirty'\n",
        "    while n_patch_status == 'dirty':\n",
        "      # generate a negative patch candidate with the same dimension as the positive patch but located randomly elsewhere in the image\n",
        "      xA1 = np.random.randint(0,max_xA1)\n",
        "      yA1 = np.random.randint(0,max_yA1)\n",
        "      xA2 = xA1 + wA\n",
        "      yA2 = yA1 + hA\n",
        "      polyA = Polygon([(xA1,yA1),(xA2,yA1),(xA2,yA2),(xA1,yA2),(xA1,yA1)])\n",
        "      # p1 = Point(xA1,yA1)\n",
        "      # p2 = Point(xA1,yA2)\n",
        "      # p3 = Point(xA2,yA1)\n",
        "      # p4 = Point(xA2,yA2)\n",
        "      # print (f'w range: {wA}, h range: {hA}, xA1 = {xA1}, yA1 = {yA1}')\n",
        "      # check the negative patch candidate against each of the positive patches\n",
        "      for boxB in boxes_positive_patches:\n",
        "        xB1 = boxB[0]\n",
        "        yB1 = boxB[1]\n",
        "        wB = boxB[2]\n",
        "        hB = boxB[3]\n",
        "        xB2 = xB1 + wB\n",
        "        yB2 = yB1 + hB\n",
        "        polyB = Polygon([(xB1,yB1),(xB2,yB1),(xB2,yB2),(xB1,yB2),(xB1,yB1)])\n",
        "        #if ((xB1<=xA1<=xB2 and yB1<=yA1<=yB2) or (xB1<=xA1<=xB2 and yB1<=yA1<=yB2) or (xB1<=xA1<=xB2 and yB1<=yA1<=yB2))\n",
        "        # if any corner of the negative patch candidate falls within the positive patch, disregard and generate a new one\n",
        "        #if p1.within(polyB) == 'True' or p2.within(polyB) == 'True' or p3.within(polyB) == 'True' or p4.within(polyB) == 'True':\n",
        "        if Polygon(polyA).intersects(Polygon(polyB)):\n",
        "          n_patch_status = 'dirty'\n",
        "          break\n",
        "        # else temporarily set the negative patch candidate as clean\n",
        "        else:\n",
        "          n_patch_status = 'clean'\n",
        "      # after a particular negative patch candidate has been confirmed not intersecting with any of the positive patches, extract it.\n",
        "      if n_patch_status == 'clean':\n",
        "        negative_patch = np.squeeze(image_patches)\n",
        "        negative_patch = negative_patch[int(yA1):int(yA2),int(xA1):int(xA2)]\n",
        "        negative_patches.append(negative_patch)\n",
        "\n",
        "        ########### show negative patches ###########\n",
        "\n",
        "        # plt.imshow(negative_patch)\n",
        "        # plt.show()\n",
        "\n",
        "  ############## extract negative patches end ###############\n",
        "\n",
        "  detected_frames.append(image)\n",
        "  boxes_positive_patches_array.append(boxes_positive_patches)\n",
        "\n",
        "  ########### show image ########### \n",
        "\n",
        "  #show image\n",
        "  # print(\"This image:\")\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "\n",
        "print('Detected people in ' + str(len(detected_frames)) + ' frames which are stored in the detected_images array')\n",
        "print('Extracted ' + str(len(positive_patches)) + ' positive patches which are stored in the positive_patches array')\n",
        "print('Extracted ' + str(len(negative_patches)) + ' negative patches which are stored in the negative_patches array')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Detected people in 31 frames which are stored in the detected_images array\nExtracted 475 positive patches which are stored in the positive_patches array\nExtracted 475 negative patches which are stored in the negative_patches array\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "iHnt5lFWxTmi",
        "outputId": "405e633f-5dd5-4379-fc3a-239fb7d0e664"
      },
      "source": [
        "## Function to compute Local Binary Pattern (LBP) \n",
        "\n",
        "# source: https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
        "def LBP(images, numPoints, radius, eps=1e-7):\n",
        "    # compute the Local Binary Pattern representation\n",
        "    # of the image, and then use the LBP representation\n",
        "    # to build the histogram of patterns\n",
        "    features = []\n",
        "    for count,image in enumerate(images):\n",
        "        if image.shape[1] != 0:\n",
        "          gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "          lbp = feature.local_binary_pattern(gray, numPoints,\n",
        "              radius, method=\"uniform\")\n",
        "          (hist, _) = np.histogram(lbp.ravel(),\n",
        "              bins=np.arange(0, numPoints + 3),\n",
        "              range=(0, numPoints + 2))\n",
        "\n",
        "          # normalize the histogram\n",
        "          hist = hist.astype(\"float\")\n",
        "          hist /= (hist.sum() + eps)\n",
        "\n",
        "          # return the histogram of Local Binary Patterns\n",
        "          features.append(hist)\n",
        "    return features\n",
        "negative_patches_LBP = LBP(images=np.array(negative_patches), numPoints=24, radius=8)\n",
        "positive_patches_LBP = LBP(images=np.array(positive_patches), numPoints=24, radius=8)\n",
        "\n",
        "plt.imshow(positive_patches_LBP[0].reshape(1, -1))\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"47.754267pt\" version=\"1.1\" viewBox=\"0 0 380.482812 47.754267\" width=\"380.482812pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-12-13T14:41:34.815761</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 47.754267 \r\nL 380.482812 47.754267 \r\nL 380.482812 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 38.482813 23.876142 \r\nL 373.282813 23.876142 \r\nL 373.282813 10.999219 \r\nL 38.482813 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p55bb1fd367)\">\r\n    <image height=\"13\" id=\"image541a675141\" transform=\"scale(1 -1)translate(0 -13)\" width=\"335\" x=\"38.482813\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAU8AAAANCAYAAAApKuwhAAAAmElEQVR4nO3UsRGCQBCGUQ6IyK3JUizRAqzCPjQRhrOG/UfU4L18Z7mb42vn06UPX9Afz8N37K/18B2pNrb60DR9/kN+qFXPs+/lHX3byjNtnssz//zWhl6/t6EHGWjFNx3sGJelPJP8N9f7rTwzlicAEE+AhHgCBMQTICCeAAHxBAiIJ0BAPAEC4gkQEE+AgHgCBMQTIPAGniIYIbmLs14AAAAASUVORK5CYII=\" y=\"-10.876142\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"ma61f1b4d74\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.921274\" xlink:href=\"#ma61f1b4d74\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(41.740024 38.474579)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"109.305889\" xlink:href=\"#ma61f1b4d74\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(106.124639 38.474579)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.690505\" xlink:href=\"#ma61f1b4d74\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(167.328005 38.474579)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.07512\" xlink:href=\"#ma61f1b4d74\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(231.71262 38.474579)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.459736\" xlink:href=\"#ma61f1b4d74\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(296.097236 38.474579)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"366.844351\" xlink:href=\"#ma61f1b4d74\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(360.481851 38.474579)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m58f6590484\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m58f6590484\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- −0.5 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.59375 35.5 \r\nL 73.1875 35.5 \r\nL 73.1875 27.203125 \r\nL 10.59375 27.203125 \r\nz\r\n\" id=\"DejaVuSans-8722\"/>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m58f6590484\" y=\"17.43768\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(15.579688 21.236899)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m58f6590484\" y=\"23.876142\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(15.579688 27.675361)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 38.482813 23.876142 \r\nL 38.482813 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 373.282813 23.876142 \r\nL 373.282813 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 38.482813 23.876142 \r\nL 373.282813 23.876142 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 38.482813 10.999219 \r\nL 373.282813 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p55bb1fd367\">\r\n   <rect height=\"12.876923\" width=\"334.8\" x=\"38.482813\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdtkdcW1s23R",
        "outputId": "30cc7523-8ffc-4965-eee9-ab7ddc004061",
        "tags": []
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for p in positive_patches_LBP:\n",
        "  x.append(p)\n",
        "  y.append(1)\n",
        "\n",
        "for n in negative_patches_LBP:\n",
        "  x.append(n)\n",
        "  y.append(-1)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(710, 26) (710,)\n(237, 26) (237,)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFrcTyTX88dO"
      },
      "source": [
        "cvxopt.solvers.options['show_progress'] = False\n",
        "\n",
        "class mySVM():\n",
        "\tdef __init__(self,kernel=\"rbf\",polyconst=1,gamma=10,degree=2):\n",
        "\t\tself.kernel = kernel\n",
        "\t\tself.polyconst = float(1)\n",
        "\t\tself.gamma = float(gamma)\n",
        "\t\tself.degree = degree\n",
        "\t\tself._support_vectors = None\n",
        "\t\tself._alphas = None\n",
        "\t\tself.intercept = None\n",
        "\t\tself._n_support = None\n",
        "\t\tself.weights = None\n",
        "\t\tself._support_labels = None\n",
        "\t\tself._indices = None\n",
        "\n",
        "\tdef rbf(self,x,y):\n",
        "\t\treturn np.exp(-1.0*self.gamma*np.dot(np.subtract(x,y).T,np.subtract(x,y)))\n",
        "\n",
        "\tdef transform(self,X):\n",
        "\t\tK = np.zeros([X.shape[0],X.shape[0]])\n",
        "\t\tfor i in range(X.shape[0]):\n",
        "\t\t\tfor j in range(X.shape[0]):\n",
        "\t\t\t\tK[i,j] = self.rbf(X[i],X[j])\n",
        "\t\treturn K\n",
        "\n",
        "\tdef fit(self,data,labels):\n",
        "\t\tnum_data, num_features = data.shape\n",
        "\t\tlabels = labels.astype(np.double)\n",
        "\t\tK = self.transform(data)\n",
        "\t\tP = cvxopt.matrix(np.outer(labels,labels)*K)\n",
        "\t\tq = cvxopt.matrix(np.ones(num_data)*-1)\n",
        "\t\tA = cvxopt.matrix(labels,(1,num_data))\n",
        "\t\tb = cvxopt.matrix(0.0)\n",
        "\t\tG = cvxopt.matrix(np.diag(np.ones(num_data) * -1))\n",
        "\t\th = cvxopt.matrix(np.zeros(num_data))\n",
        "\n",
        "\t\talphas = np.ravel(cvxopt.solvers.qp(P, q, G, h, A, b)['x'])\n",
        "\t\tis_sv = alphas>1e-5\n",
        "\t\tself._support_vectors = data[is_sv]\n",
        "\t\tself._n_support = np.sum(is_sv)\n",
        "\t\tself._alphas = alphas[is_sv]\n",
        "\t\tself._support_labels = labels[is_sv]\n",
        "\t\tself._indices = np.arange(num_data)[is_sv]\n",
        "\t\tself.intercept = 0\n",
        "\t\tfor i in range(self._alphas.shape[0]):\n",
        "\t\t\tself.intercept += self._support_labels[i] \n",
        "\t\t\tself.intercept -= np.sum(self._alphas*self._support_labels*K[self._indices[i],is_sv])\n",
        "\t\tself.intercept /= self._alphas.shape[0]\n",
        "\n",
        "\tdef predict(self,X):\n",
        "\t\tif self.kernel==\"linear\":\n",
        "\t\t\tscore = np.dot(X,self.weights)+self.intercept\n",
        "\t\telse:\n",
        "\t\t\tscore = np.zeros(X.shape[0])\n",
        "\t\t\tfor i in range(X.shape[0]):\n",
        "\t\t\t\ts = 0\n",
        "\t\t\t\tfor alpha,label,sv in zip(self._alphas,self._support_labels,self._support_vectors):\n",
        "\t\t\t\t\ts += alpha*label*self.rbf(X[i],sv)\n",
        "\t\t\t\tscore[i] = s\n",
        "\t\t\tscore = score + self.intercept\n",
        "\t\treturn np.where(score>0,1,-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY1ekm4-9B6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09785bfe-bb77-4d14-8347-3789ffad8dc7"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = mySVM(kernel=\"poly\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='poly')\n",
        "svclassifier.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVC(kernel='poly')"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rb5iDYKHB5E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4JzQONh8-Sf",
        "outputId": "295f7589-7a25-4709-93d1-c6f2b42f4005",
        "tags": []
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "prediction2 = svclassifier.predict(X_test)\n",
        "\n",
        "correct1 = 0\n",
        "correct2 = 0\n",
        "for i in range(len(list(y_test))):\n",
        "  if y_test[i] == prediction[i]:\n",
        "    correct1 += 1\n",
        "  if y_test[i] == prediction2[i]:\n",
        "    correct2 += 1\n",
        "\n",
        "\n",
        "print(correct1/len(list(y_test)))\n",
        "print(correct2/len(list(y_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.7637130801687764\n0.7679324894514767\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0\nimage: seq_000001.jpg people count: 26\n1\nimage: seq_000002.jpg people count: 21\n2\nimage: seq_000003.jpg people count: 26\n3\nimage: seq_000004.jpg people count: 25\n4\nimage: seq_000005.jpg people count: 27\n5\nimage: seq_000006.jpg people count: 27\n6\nimage: seq_000007.jpg people count: 37\n7\nimage: seq_000008.jpg people count: 29\n8\nimage: seq_000009.jpg people count: 24\n9\nimage: seq_000010.jpg people count: 27\n10\nimage: seq_000011.jpg people count: 29\n11\nimage: seq_000012.jpg people count: 29\n12\nimage: seq_000013.jpg people count: 37\n13\nimage: seq_000014.jpg people count: 29\n14\nimage: seq_000015.jpg people count: 36\n15\nimage: seq_000016.jpg people count: 24\n16\nimage: seq_000017.jpg people count: 23\n17\nimage: seq_000018.jpg people count: 21\n18\nimage: seq_000019.jpg people count: 33\n19\nimage: seq_000020.jpg people count: 33\n20\nimage: seq_000021.jpg people count: 30\n21\nimage: seq_000022.jpg people count: 29\n22\nimage: seq_000023.jpg people count: 31\n23\nimage: seq_000024.jpg people count: 29\n24\nimage: seq_000025.jpg people count: 23\n25\nimage: seq_000026.jpg people count: 30\n26\nimage: seq_000027.jpg people count: 34\n27\nimage: seq_000028.jpg people count: 30\n28\nimage: seq_000029.jpg people count: 21\n29\nimage: seq_000030.jpg people count: 28\n30\nimage: seq_000031.jpg people count: 23\n"
        }
      ],
      "source": [
        "predictions_per_image = []\n",
        "svm_boxes_array = []\n",
        "for count,image_path in enumerate(os.listdir(path_frames)):\n",
        "    if count >= len(detected_frames):\n",
        "        break\n",
        "    #sliding window along one frame\n",
        "    input_path = os.path.join(path_frames, image_path)\n",
        "    image = plt.imread(input_path)\n",
        "    # print(image.shape)\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "    windows = []\n",
        "    our_boxes = []\n",
        "    #sliding window, window size grows as we go down\n",
        "    for a in range(0,621,20):\n",
        "        for b in range(0,101,50):\n",
        "            temp_image = image[b:b+50,a:a+20]\n",
        "            windows.append(temp_image)\n",
        "            our_boxes.append([b, a, 50, 20])\n",
        "    for a in range(0,601,40):\n",
        "        for b in range(100,301,50):\n",
        "            temp_image = image[b:b+90,a:a+40]\n",
        "            windows.append(temp_image)\n",
        "            our_boxes.append([b, a, 90, 40])\n",
        "    for a in range(0,591,10):\n",
        "        for b in range(300,381,80):\n",
        "            temp_image = image[b:b+100,a:a+50]\n",
        "            windows.append(temp_image)\n",
        "            our_boxes.append([b, a, 100, 50])\n",
        "\n",
        "\n",
        "    # plt.figure(figsize=(5, 5))\n",
        "    # plt.imshow(windows[-1])\n",
        "    # plt.show()\n",
        "    # print('Detected ' + str(len(windows)) + ' windows.')\n",
        "\n",
        "    np_windows = np.array(windows)\n",
        "    # print(np_windows.shape)\n",
        "    # print(\"getting features\")\n",
        "    test_windows = LBP(images=np_windows, numPoints=24, radius=8)\n",
        "    # print(\"making predictions\")\n",
        "    predictions = model.predict(np.array(test_windows))\n",
        "    #put in seperate block so you don't rerun the last block\n",
        "    pos_windows = []\n",
        "    our_pos_boxes = []\n",
        "    for i in range(len(predictions)):\n",
        "        if (predictions[i] == 1):\n",
        "            pos_windows.append(np_windows[i])\n",
        "            our_pos_boxes.append(our_boxes[i])\n",
        "    np_pos_windows = np.array(pos_windows)\n",
        "\n",
        "    # print(np_pos_windows.shape)\n",
        "    # for im in np_pos_windows:\n",
        "    #   plt.imshow(im)\n",
        "    #   plt.show()\n",
        "\n",
        "\n",
        "    delete = []\n",
        "    for f in range(np_pos_windows.shape[0]):\n",
        "        delete.append(1)\n",
        "    for a in range(np_pos_windows.shape[0]):\n",
        "        if (delete[a] == 1):\n",
        "            hsv1 = cv2.cvtColor(np_pos_windows[a], cv2.COLOR_BGR2HSV)\n",
        "            hist1 = cv2.calcHist([hsv1], [0,1], None, [180,256], [0,180,0,256])\n",
        "            cv2.normalize(hist1, hist1, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "            for b in range(np_pos_windows.shape[0]):\n",
        "                if (delete[b]==1):\n",
        "                    hsv2 = cv2.cvtColor(np_pos_windows[b], cv2.COLOR_BGR2HSV)\n",
        "                    hist2 = cv2.calcHist([hsv2], [0,1], None, [180,256], [0,180,0,256])\n",
        "                    cv2.normalize(hist2, hist2, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "                    difference = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
        "                    #print(difference)\n",
        "                    if (difference > 0.30 and b != a):\n",
        "                        delete[b] = 0\n",
        "\n",
        "    # print(delete)\n",
        "\n",
        "    im = image.copy()\n",
        "    people_count = 0\n",
        "    positive_boxes = []\n",
        "    for i in range(len(np_pos_windows)):\n",
        "        if (delete[i] != 0):\n",
        "            # draw selected boxes in the original image\n",
        "            cv2.rectangle(im, (round(our_pos_boxes[i][1]),round(our_pos_boxes[i][0])), (round(our_pos_boxes[i][1]+our_pos_boxes[i][3]),round(our_pos_boxes[i][0]+our_pos_boxes[i][2])), (255, 0, 0), 2)\n",
        "            people_count += 1\n",
        "            positive_boxes.append(our_pos_boxes[i])\n",
        "\n",
        "    # only keep as many boxes as yolo frames for IoU computation\n",
        "    if count < len(detected_frames):\n",
        "        svm_boxes_array.append(positive_boxes)\n",
        "        print(count)\n",
        "                \n",
        "        \n",
        "    # plt.figure(figsize=(15, 15))\n",
        "    # plt.imshow(im)\n",
        "    # plt.show()\n",
        "    print(\"image: \" + str(image_path) + \" people count: \" + str(people_count)) \n",
        "    predictions_per_image.append([count+1, people_count])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "IoU:0.1769772970861959\n"
        }
      ],
      "source": [
        "\n",
        "# Making masks from bounding boxes for each frame\n",
        "def make_mask(frame, bounding_boxes, yolo=True):\n",
        "    # \ta- initialise mask (numpy array) of frame size to 0s.\n",
        "    mask = np.zeros((frame.shape[0], frame.shape[1]))\n",
        "    # \tb- for each bounding box in frame, set \n",
        "    for box in bounding_boxes:\n",
        "        x = int(box[0])\n",
        "        y = int(box[1])\n",
        "        w = int(box[2])\n",
        "        h = int(box[3])\n",
        "        ## TODO: FIX THE BOX X,Y Conventions to avoid the code below\n",
        "        if yolo:\n",
        "            mask[y: y+h, x: x+w] = 255\n",
        "        else: \n",
        "            mask[x: x+w, y: y+h] = 255\n",
        "\n",
        "    \n",
        "    return mask\n",
        "\n",
        "# Calculating IoU\n",
        "intersections = []\n",
        "unions = []\n",
        "for count, frame in enumerate(detected_frames):\n",
        "    yolo_mask = make_mask(frame, boxes_positive_patches_array[count])\n",
        "    svm_mask = make_mask(frame, svm_boxes_array[count], yolo=False)\n",
        "\n",
        "    # Calculating IoU\n",
        "    intersections.append(np.logical_and(yolo_mask, svm_mask))\n",
        "    unions.append(np.logical_or(yolo_mask, svm_mask))\n",
        "\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    # plt.imshow(yolo_mask)\n",
        "    # plt.subplot(1, 2, 2)\n",
        "    # plt.imshow(svm_mask)\n",
        "    # plt.show()\n",
        "\n",
        "print(\"IoU:\" + str(np.sum(intersections) / np.sum(unions)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import csv  \n",
        "    \n",
        "# field names  \n",
        "fields = ['id', 'count']  \n",
        "    \n",
        "# data rows of csv file  \n",
        "rows = predictions_per_image\n",
        "\n",
        "# name of csv file  \n",
        "filename = \"group21_submission.csv\"\n",
        "    \n",
        "# writing to csv file  \n",
        "with open(filename, 'w', newline='') as csvfile:  \n",
        "    # creating a csv writer object  \n",
        "    csvwriter = csv.writer(csvfile)  \n",
        "        \n",
        "    # writing the fields  \n",
        "    csvwriter.writerow(fields)  \n",
        "        \n",
        "    # writing the data rows  \n",
        "    csvwriter.writerows(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbk8tUuk0vDP"
      },
      "source": [
        "## Todo:\n",
        "- Fix bug that happens if we extract from more than 9 images\n",
        "- Decide which feature to use between HoG, Haar, LBP, or other\n",
        "- Modify SVM code we got to make it less sus\n",
        "- Tune parameters of SVM to improve results\n",
        "- Duplicate elimination\n",
        "- Test it"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ECSE415_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}