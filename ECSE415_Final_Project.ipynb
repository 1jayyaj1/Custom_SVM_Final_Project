{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECSE415_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o91lCmRsPHeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e195aef-4ad6-4641-bd89-7dcc25fa89aa"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numpy import random\n",
        "from shapely.geometry import Point, Polygon\n",
        "from skimage import feature\n",
        "import os\n",
        "import cvxopt\n",
        "import cvxopt.solvers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# path = '/content/drive/MyDrive/Colab_Notebooks/ECSE415_Final_Project/' # Kun's path, comment out when needed\n",
        "path = '/content/drive/MyDrive/Colab_Notebooks/ECSE415_Final_Project/' # Jay's path\n",
        "# path = './' # Kamy's path"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4Ag07uPJPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1234a3-11aa-49b7-c7dd-5ca8c4ca4e6f"
      },
      "source": [
        "# Inspired from https://medium.com/@luanaebio/detecting-people-with-yolo-and-opencv-5c1f9bc6a810\n",
        "\n",
        "images = []\n",
        "path_frames = path + 'frames/'\n",
        "detected_frames = []\n",
        "positive_patches = []\n",
        "negative_patches = []\n",
        "\n",
        "\n",
        "# load images from frames/\n",
        "for count,image_path in enumerate(os.listdir(path_frames)):\n",
        "  if count > 50:\n",
        "    break\n",
        "  input_path = os.path.join(path_frames, image_path)\n",
        "  image = plt.imread(input_path)\n",
        "  images.append(image)\n",
        "\n",
        "Width = image.shape[1]\n",
        "Height = image.shape[0]\n",
        "\n",
        "# load class names\n",
        "classes = None\n",
        "with open(path + 'coco.names', 'r') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# read pre-trained model and config file\n",
        "net = cv2.dnn.readNet(path + 'yolov3.weights', path + 'cfg/yolov3.cfg')\n",
        "\n",
        "for image in images:\n",
        "  image_patches = image.copy()\n",
        "\n",
        "  # create input blob \n",
        "  # set input blob for the network\n",
        "  # blob = cv2.dnn.blobFromImage(image, scalefactor=?, size=?, mean substraction value=?, swapRB=?)\n",
        "  blob = cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False)\n",
        "  net.setInput(blob)\n",
        "\n",
        "  # run inference through the network\n",
        "  layer_names = net.getLayerNames()\n",
        "  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "  # gather predictions from output layers\n",
        "  outs = net.forward(output_layers)\n",
        "\n",
        "  # initiatialization\n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = []\n",
        "  conf_threshold = 0.5\n",
        "  nms_threshold = 0.4\n",
        "  boxes_positive_patches = []\n",
        "\n",
        "  # for each detetion from each output layer get the confidence, class id, bounding box params and ignore weak detections (confidence < 0.5) \n",
        "  for out in outs:\n",
        "    for detection in out:\n",
        "      scores = detection[5:] # from 0-4, is matched box coordinates/dimension info, from 5 onwards is an array of confidence scores towards each different class in classes\n",
        "      class_id = np.argmax(scores) # return the index of max confidence\n",
        "      confidence = scores[class_id] # get the confidence score\n",
        "      if confidence > conf_threshold:\n",
        "        center_x = int(detection[0] * Width)\n",
        "        center_y = int(detection[1] * Height)\n",
        "        w = int(detection[2] * Width)\n",
        "        h = int(detection[3] * Height)\n",
        "        x = center_x - w / 2\n",
        "        y = center_y - h / 2\n",
        "\n",
        "        #####################################\n",
        "        #                                   #\n",
        "        #  moved \"extract positive patches\" #\n",
        "        #  part from here to post NMS to    #\n",
        "        #  further remove duplicated ones   #\n",
        "        #                                   #\n",
        "        #####################################\n",
        "\n",
        "        # store captured class_id number\n",
        "        class_ids.append(class_id)\n",
        "        # store the confidence towards the above class_id\n",
        "        confidences.append(float(confidence))\n",
        "        # store the captured boxes\n",
        "        boxes.append([x, y, w, h])\n",
        "        # Would need to generate negative patch here and append it to negative_patches array\n",
        "\n",
        "  # apply non-max suppression: extract the highest confidence box index among all partially overlapped boxes\n",
        "  indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold )\n",
        "\n",
        "  print(\"Positive patches of this image:\")\n",
        "\n",
        "  #check if is people detection, if so, draw boxes in the original image, and extract positive patches\n",
        "  for i in indices:\n",
        "    i = i[0] # i was a 1x1 array, make it a scaler for indexing into boxes\n",
        "    box = boxes[i]\n",
        "    if class_ids[i]==0:\n",
        "      label = str(classes[class_id])\n",
        "\n",
        "      ################ extract positive patches starts ##############\n",
        "\n",
        "      x = box[0]\n",
        "      y = box[1]\n",
        "      w = box[2]\n",
        "      h = box[3]\n",
        "      if w > 100 or w < 1 or h > 200 or h < 1:\n",
        "        continue\n",
        "      positive_patch = np.squeeze(image_patches)\n",
        "      positive_patch = positive_patch[int(y):int(y+h),int(x):int(x+w)]\n",
        "      positive_patches.append(positive_patch)\n",
        "\n",
        "      # extract positive patch box in an array \n",
        "      boxes_positive_patches.append(box)\n",
        "\n",
        "      # show positive patches\n",
        "      # plt.imshow(positive_patch)\n",
        "      # plt.show()\n",
        "\n",
        "      ############### extract positive patches end #################\n",
        "      \n",
        "      # draw selected boxes in the original image\n",
        "      cv2.rectangle(image, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (255, 0, 0), 2)\n",
        "      cv2.putText(image, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "  ############## extract negative patches start ###############\n",
        "\n",
        "  print(\"Negative patches of this image\")\n",
        "\n",
        "  # foreach positie patch, create a negative patch at a random location that does not intersect with any of the positive patches\n",
        "  for boxA in boxes_positive_patches:\n",
        "\n",
        "    # extract positive patch dimension\n",
        "    wA = boxA[2]\n",
        "    hA = boxA[3]\n",
        "\n",
        "    max_xA1 = Width - wA\n",
        "    max_yA1 = Height - hA\n",
        "\n",
        "    # initialize the random image status to dirty until loop through all positive patches to confirm no intersactions\n",
        "    n_patch_status = 'dirty'\n",
        "\n",
        "    # generate negative patch candidates if patch status is 'dirty'\n",
        "    while n_patch_status == 'dirty':\n",
        "      # generate a negative patch candidate with the same dimension as the positive patch but located randomly elsewhere in the image\n",
        "      xA1 = np.random.randint(0,max_xA1)\n",
        "      yA1 = np.random.randint(0,max_yA1)\n",
        "      xA2 = xA1 + wA\n",
        "      yA2 = yA1 + hA\n",
        "      polyA = ([(xA1,yA1),(xA1,yA2),(xA2,yA1),(xA2,yA2)])\n",
        "      # p1 = Point(xA1,yA1)\n",
        "      # p2 = Point(xA1,yA2)\n",
        "      # p3 = Point(xA2,yA1)\n",
        "      # p4 = Point(xA2,yA2)\n",
        "      # print (f'w range: {wA}, h range: {hA}, xA1 = {xA1}, yA1 = {yA1}')\n",
        "      # check the negative patch candidate against each of the positive patches\n",
        "      for boxB in boxes_positive_patches:\n",
        "        xB1 = boxB[0]\n",
        "        yB1 = boxB[1]\n",
        "        wB = boxB[2]\n",
        "        hB = boxB[3]\n",
        "        xB2 = xB1 + wB\n",
        "        yB2 = yB1 + hB\n",
        "        polyB = Polygon([(xB1,yB1),(xB1,yB2),(xB2,yB1),(xB2,yB2)])\n",
        "        #if ((xB1<=xA1<=xB2 and yB1<=yA1<=yB2) or (xB1<=xA1<=xB2 and yB1<=yA1<=yB2) or (xB1<=xA1<=xB2 and yB1<=yA1<=yB2))\n",
        "        # if any corner of the negative patch candidate falls within the positive patch, disregard and generate a new one\n",
        "        #if p1.within(polyB) == 'True' or p2.within(polyB) == 'True' or p3.within(polyB) == 'True' or p4.within(polyB) == 'True':\n",
        "        if Polygon(polyA).intersects(Polygon(polyB)):\n",
        "          n_patch_status = 'dirty'\n",
        "          break\n",
        "        # else temporarily set the negative patch candidate as clean\n",
        "        else:\n",
        "          n_patch_status = 'clean'\n",
        "      # after a particular negative patch candidate has been confirmed not intersecting with any of the positive patches, extract it.\n",
        "      if n_patch_status == 'clean':\n",
        "        negative_patch = np.squeeze(image_patches)\n",
        "        negative_patch = negative_patch[int(yA1):int(yA2),int(xA1):int(xA2)]\n",
        "        negative_patches.append(negative_patch)\n",
        "\n",
        "        # show negative patches\n",
        "        # plt.imshow(negative_patch)\n",
        "        # plt.show()\n",
        "\n",
        "  ############## extract negative patches end ###############\n",
        "\n",
        "\n",
        "  # show image\n",
        "  print(\"Tihs image:\")\n",
        "  detected_frames.append(image)\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "print('Detected people in ' + str(len(detected_frames)) + ' frames which are stored in the detected_images array')\n",
        "print('Extracted ' + str(len(positive_patches)) + ' positive patches which are stored in the positive_patches array')\n",
        "print('Extracted ' + str(len(negative_patches)) + ' negative patches which are stored in the negative_patches array')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Positive patches of this image:\n",
            "Negative patches of this image\n",
            "Detected people in 0 frames which are stored in the detected_images array\n",
            "Extracted 994 positive patches which are stored in the positive_patches array\n",
            "Extracted 994 negative patches which are stored in the negative_patches array\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "iHnt5lFWxTmi",
        "outputId": "e6593bee-2fc9-472b-cd39-cf75ce55523d"
      },
      "source": [
        "## Function to compute Local Binary Pattern (LBP) \n",
        "\n",
        "# source: https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
        "def LBP(images, numPoints, radius, eps=1e-7):\n",
        "    # compute the Local Binary Pattern representation\n",
        "    # of the image, and then use the LBP representation\n",
        "    # to build the histogram of patterns\n",
        "    features = []\n",
        "    for count,image in enumerate(images):\n",
        "        if image.shape[1] != 0:\n",
        "          gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "          lbp = feature.local_binary_pattern(gray, numPoints,\n",
        "              radius, method=\"uniform\")\n",
        "          (hist, _) = np.histogram(lbp.ravel(),\n",
        "              bins=np.arange(0, numPoints + 3),\n",
        "              range=(0, numPoints + 2))\n",
        "\n",
        "          # normalize the histogram\n",
        "          hist = hist.astype(\"float\")\n",
        "          hist /= (hist.sum() + eps)\n",
        "\n",
        "          # return the histogram of Local Binary Patterns\n",
        "          features.append(hist)\n",
        "    return features\n",
        "negative_patches_LBP = LBP(images=np.array(negative_patches), numPoints=24, radius=8)\n",
        "positive_patches_LBP = LBP(images=np.array(positive_patches), numPoints=24, radius=8)\n",
        "\n",
        "plt.imshow(positive_patches_LBP[0].reshape(1, -1))\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdtkdcW1s23R",
        "outputId": "01a2c872-2a29-4054-b59b-90250f5c4939"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for p in positive_patches_LBP:\n",
        "  x.append(p)\n",
        "  y.append(1)\n",
        "\n",
        "for n in negative_patches_LBP:\n",
        "  x.append(n)\n",
        "  y.append(-1)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1486, 26) (1486,)\n",
            "(496, 26) (496,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFrcTyTX88dO"
      },
      "source": [
        "cvxopt.solvers.options['show_progress'] = False\n",
        "\n",
        "class mySVM():\n",
        "\tdef __init__(self,kernel=\"rbf\",polyconst=1,gamma=10,degree=2):\n",
        "\t\tself.kernel = kernel\n",
        "\t\tself.polyconst = float(1)\n",
        "\t\tself.gamma = float(gamma)\n",
        "\t\tself.degree = degree\n",
        "\t\tself._support_vectors = None\n",
        "\t\tself._alphas = None\n",
        "\t\tself.intercept = None\n",
        "\t\tself._n_support = None\n",
        "\t\tself.weights = None\n",
        "\t\tself._support_labels = None\n",
        "\t\tself._indices = None\n",
        "\n",
        "\tdef rbf(self,x,y):\n",
        "\t\treturn np.exp(-1.0*self.gamma*np.dot(np.subtract(x,y).T,np.subtract(x,y)))\n",
        "\n",
        "\tdef transform(self,X):\n",
        "\t\tK = np.zeros([X.shape[0],X.shape[0]])\n",
        "\t\tfor i in range(X.shape[0]):\n",
        "\t\t\tfor j in range(X.shape[0]):\n",
        "\t\t\t\tK[i,j] = self.rbf(X[i],X[j])\n",
        "\t\treturn K\n",
        "\n",
        "\tdef fit(self,data,labels):\n",
        "\t\tnum_data, num_features = data.shape\n",
        "\t\tlabels = labels.astype(np.double)\n",
        "\t\tK = self.transform(data)\n",
        "\t\tP = cvxopt.matrix(np.outer(labels,labels)*K)\n",
        "\t\tq = cvxopt.matrix(np.ones(num_data)*-1)\n",
        "\t\tA = cvxopt.matrix(labels,(1,num_data))\n",
        "\t\tb = cvxopt.matrix(0.0)\n",
        "\t\tG = cvxopt.matrix(np.diag(np.ones(num_data) * -1))\n",
        "\t\th = cvxopt.matrix(np.zeros(num_data))\n",
        "\n",
        "\t\talphas = np.ravel(cvxopt.solvers.qp(P, q, G, h, A, b)['x'])\n",
        "\t\tis_sv = alphas>1e-5\n",
        "\t\tself._support_vectors = data[is_sv]\n",
        "\t\tself._n_support = np.sum(is_sv)\n",
        "\t\tself._alphas = alphas[is_sv]\n",
        "\t\tself._support_labels = labels[is_sv]\n",
        "\t\tself._indices = np.arange(num_data)[is_sv]\n",
        "\t\tself.intercept = 0\n",
        "\t\tfor i in range(self._alphas.shape[0]):\n",
        "\t\t\tself.intercept += self._support_labels[i] \n",
        "\t\t\tself.intercept -= np.sum(self._alphas*self._support_labels*K[self._indices[i],is_sv])\n",
        "\t\tself.intercept /= self._alphas.shape[0]\n",
        "\n",
        "\tdef predict(self,X):\n",
        "\t\tif self.kernel==\"linear\":\n",
        "\t\t\tscore = np.dot(X,self.weights)+self.intercept\n",
        "\t\telse:\n",
        "\t\t\tscore = np.zeros(X.shape[0])\n",
        "\t\t\tfor i in range(X.shape[0]):\n",
        "\t\t\t\ts = 0\n",
        "\t\t\t\tfor alpha,label,sv in zip(self._alphas,self._support_labels,self._support_vectors):\n",
        "\t\t\t\t\ts += alpha*label*self.rbf(X[i],sv)\n",
        "\t\t\t\tscore[i] = s\n",
        "\t\t\tscore = score + self.intercept\n",
        "\t\treturn np.where(score>0,1,-1)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY1ekm4-9B6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f14a528-4080-4f55-883e-e643be3f3201"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = mySVM(kernel=\"poly\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='poly')\n",
        "svclassifier.fit(X_train, y_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rb5iDYKHB5E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4JzQONh8-Sf",
        "outputId": "babd8d3c-2c14-41db-e88a-82b550c6e7d8"
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "prediction2 = svclassifier.predict(X_test)\n",
        "\n",
        "correct1 = 0\n",
        "correct2 = 0\n",
        "for i in range(len(list(y_test))):\n",
        "  if y_test[i] == prediction[i]:\n",
        "    correct1 += 1\n",
        "  if y_test[i] == prediction2[i]:\n",
        "    correct2 += 1\n",
        "\n",
        "\n",
        "print(correct1/len(list(y_test)))\n",
        "print(correct2/len(list(y_test)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7701612903225806\n",
            "0.7641129032258065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbk8tUuk0vDP"
      },
      "source": [
        "## Todo:\n",
        "- Fix bug that happens if we extract from more than 9 images\n",
        "- Decide which feature to use between HoG, Haar, LBP, or other\n",
        "- Modify SVM code we got to make it less sus\n",
        "- Tune parameters of SVM to improve results\n",
        "- Duplicate elimination\n",
        "- Test it"
      ]
    }
  ]
}