{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECSE415_Final_Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o91lCmRsPHeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c176da5a-8355-485f-d691-8282980772db"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numpy import random\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/My Drive/Colab_Notebooks/ECSE415_Final_Project/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4Ag07uPJPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c629e6-cb1c-4d7d-aba9-59db8c0ad6c3"
      },
      "source": [
        "# Inspired from https://medium.com/@luanaebio/detecting-people-with-yolo-and-opencv-5c1f9bc6a810\n",
        "\n",
        "images = []\n",
        "path_frames = path + 'frames/'\n",
        "detected_frames = []\n",
        "positive_patches = []\n",
        "negative_patches = []\n",
        "\n",
        "for count,image_path in enumerate(os.listdir(path_frames)):\n",
        "  if count > 99:\n",
        "    break\n",
        "  input_path = os.path.join(path_frames, image_path)\n",
        "  image = plt.imread(input_path)\n",
        "  images.append(image)\n",
        "\n",
        "classes = None\n",
        "with open(path + 'coco.names', 'r') as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "Width = image.shape[1]\n",
        "Height = image.shape[0]\n",
        "\n",
        "# read pre-trained model and config file\n",
        "net = cv2.dnn.readNet(path + 'yolov3.weights', path + 'cfg/yolov3.cfg')\n",
        "\n",
        "for image in images:\n",
        "  image_patches = image.copy()\n",
        "  # create input blob \n",
        "  # set input blob for the network\n",
        "  net.setInput(cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False))\n",
        "\n",
        "  # run inference through the network\n",
        "  # and gather predictions from output layers\n",
        "\n",
        "  layer_names = net.getLayerNames()\n",
        "  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "  outs = net.forward(output_layers)\n",
        "\n",
        "\n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = []\n",
        "\n",
        "  #create bounding box \n",
        "  for out in outs:\n",
        "      for detection in out:\n",
        "          scores = detection[5:]\n",
        "          class_id = np.argmax(scores)\n",
        "          confidence = scores[class_id]\n",
        "          if confidence > 0.1:\n",
        "              center_x = int(detection[0] * Width)\n",
        "              center_y = int(detection[1] * Height)\n",
        "              w = int(detection[2] * Width)\n",
        "              h = int(detection[3] * Height)\n",
        "              x = center_x - w / 2\n",
        "              y = center_y - h / 2\n",
        "              positive_patch = np.squeeze(image_patches)\n",
        "              positive_patch = positive_patch[int(y):int(y+h),int(x):int(x+w)]\n",
        "              positive_patches.append(positive_patch)\n",
        "              \n",
        "              # Would need to generate negative patch here and append it to negative_patches array\n",
        "              class_ids.append(class_id)\n",
        "              confidences.append(float(confidence))\n",
        "              boxes.append([x, y, w, h])\n",
        "\n",
        "\n",
        "  indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.01, 0.01)\n",
        "\n",
        "  #check if is people detection\n",
        "  for i in indices:\n",
        "      i = i[0]\n",
        "      box = boxes[i]\n",
        "      if class_ids[i]==0:\n",
        "          label = str(classes[class_id]) \n",
        "          cv2.rectangle(image, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (255, 0, 0), 2)\n",
        "          cv2.putText(image, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "  detected_frames.append(image)\n",
        "\n",
        "print('Detected people in ' + str(len(detected_frames)) + ' frames which are stored in the detected_images array')\n",
        "print('Extracted ' + str(len(patches)) + ' positive patches which are stored in the positive_patches array')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected people in 100 frames which are stored in the detected_images array\n",
            "Extracted 210 positive patches which are stored in the positive_patches array\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}